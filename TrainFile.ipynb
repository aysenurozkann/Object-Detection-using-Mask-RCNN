{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uP3azlc-UHI"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04qOTxeVvxes"
      },
      "outputs": [],
      "source": [
        "%cd /content/Mask_RCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPPEZq6HyKKD"
      },
      "source": [
        "tensorflow==1.15\n",
        "keras==2.2.5\n",
        "h5py==2.10.0\n",
        "scikit-image==0.16.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kyz8MriR-yJE"
      },
      "outputs": [],
      "source": [
        "!pip install -r ./requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhZE0-jtwKXf",
        "outputId": "53f9fea0-8417-4c3b-b58d-3807246da6ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "import cv2\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "from mrcnn import model as modellib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibdeOkxs_BuM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-oG5FpDsG0F"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/Project/train.zip -d /content/drive/MyDrive/Project/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1MbmHwvsth2"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/Project/val.zip -d /content/drive/MyDrive/Project/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WsSHnPfzBWev"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = \"/content/drive/MyDrive/Project\"\n",
        "sys.path.append(ROOT_DIR)\n",
        "\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kp4qZxsBzxj"
      },
      "outputs": [],
      "source": [
        "class CustomConfig(Config):\n",
        "    \"\"\"Configuration for training on the custom  dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"object\"\n",
        "\n",
        "\n",
        "    IMAGES_PER_GPU = 2\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 4  # Background + pudding, milk, juice, pasta\n",
        "\n",
        "    # Number of training steps per epoch\n",
        "    STEPS_PER_EPOCH = 145\n",
        "\n",
        "    # Skip detections with < 90% confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "\n",
        "config = CustomConfig()\n",
        "config.display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sQYvD8egB9k2"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(utils.Dataset):\n",
        "\n",
        "    def load_dataset(self, dataset_dir, subset):\n",
        "      \n",
        "        # Add classes.\n",
        "        self.add_class(\"object\", 1, \"Pudding\")\n",
        "        self.add_class(\"object\", 2, \"Milk\")\n",
        "        self.add_class(\"object\", 3, \"Pasta\")\n",
        "        self.add_class(\"object\", 4, \"Juice\")\n",
        "\n",
        "\n",
        "     \n",
        "        # Train or validation dataset?\n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        dataset_dir = os.path.join(dataset_dir, subset)\n",
        "        \n",
        "      \n",
        "        annotations = json.load(open(os.path.join(dataset_dir, 'annotations.json')))\n",
        "        #keep the name of the json files in the both train and val folders\n",
        "        \n",
        "        print(\"annotations\", annotations)\n",
        "        annotations = list(annotations.values())  # don't need the dict keys\n",
        "\n",
        "\n",
        "\n",
        "        # The VIA tool saves images in the JSON even if they don't have any\n",
        "        # annotations. Skip unannotated images.\n",
        "        annotations = [i for i in annotations if i['regions']]\n",
        "        \n",
        "        # Add images\n",
        "        for img in annotations:\n",
        "            print(\"img\", img)\n",
        "            # Get the x, y coordinaets of points of the polygons.\n",
        "            # There are stores in the shape_attributes (see json format above)\n",
        "            polygons = [i['shape_attributes'] for i in img['regions']] \n",
        "            objects_names = [i['region_attributes']['names'] for i in img['regions']]\n",
        "            \n",
        "            print(\"objects names:\",objects_names)\n",
        "            name_dict = {\"Pudding\": 1,\"Milk\": 2, \"Pasta\" : 3, \"Juice\" : 4}\n",
        "\n",
        "            # key = tuple(name_dict)\n",
        "            num_ids = [name_dict[i] for i in objects_names]\n",
        "            print(\"num_ids\", num_ids)\n",
        "\n",
        "            ## ADD_İMAGE FONKSİYONUNA PARAMETRELERİ GÖNDEREBİLMEK İÇİN DÜZENLEMELİYİZ\n",
        "            image_path = os.path.join(dataset_dir, img['filename'])\n",
        "            image = skimage.io.imread(image_path)\n",
        "            height, width = image.shape[:2] # returns height, width, channel\n",
        "\n",
        "            self.add_image(\n",
        "                \"object\",\n",
        "                image_id=img['filename'],  # use file name as a unique image id\n",
        "                path=image_path,\n",
        "                width=width, height=height,\n",
        "                polygons=polygons,\n",
        "                num_ids=num_ids\n",
        "                )\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"object\": # check type of the images\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        # Convert polygons to a bitmap mask of shape\n",
        "        # [height, width, instance_count]\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] != \"object\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        num_ids = info['num_ids']\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        \n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            # Get indexes of pixels inside the polygon and set them to 1\n",
        "          rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "\n",
        "          mask[rr, cc, i] = 1\n",
        "\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1s\n",
        "        # Map class names to class IDs.\n",
        "        num_ids = np.array(num_ids, dtype=np.int32)\n",
        "        return mask, num_ids #np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"object\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\t\t\t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oeOr5q7hCeWm"
      },
      "outputs": [],
      "source": [
        "def train(model):\n",
        "    # Training dataset.\n",
        "    dataset_train = CustomDataset()\n",
        "    dataset_train.load_dataset(\"/content/drive/MyDrive/Project/dataset\", \"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = CustomDataset()\n",
        "    dataset_val.load_dataset(\"/content/drive/MyDrive/Project/dataset\", \"val\")\n",
        "    dataset_val.prepare()\n",
        "\n",
        "\n",
        "    print(\"Training network heads\")\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=500,\n",
        "                layers='heads')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t0hI501DJig"
      },
      "outputs": [],
      "source": [
        "config = CustomConfig()\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "weights_path = COCO_WEIGHTS_PATH\n",
        "        # Download weights file\n",
        "if not os.path.exists(weights_path):\n",
        "  utils.download_trained_weights(weights_path)\n",
        "\n",
        "model.load_weights(weights_path, by_name=True, exclude=[\n",
        "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "train(model)\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5ZUzBkqB-En"
      },
      "outputs": [],
      "source": [
        "# we define a prediction configuration \n",
        "class PredictionConfig(Config):\n",
        "    NAME = \"object\"\n",
        "    NUM_CLASSES = 1 + 4\n",
        "    DETECTION_MIN_CONFIDENCE = 0.90\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "\n",
        "# evaluate_model is used to calculate mean Average Precision of the model\n",
        "def evaluate_model(dataset, model, cfg):\n",
        "    APs = list()\n",
        "    for image_id in dataset.image_ids:\n",
        "\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\n",
        "        scaled_image = modellib.mold_image(image, cfg)\n",
        "\n",
        "        sample = np.expand_dims(scaled_image, 0)\n",
        "\n",
        "        yhat = model.detect(sample, verbose=0)\n",
        "\n",
        "        r = yhat[0]\n",
        "\n",
        "        AP, _, _, _ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\n",
        "        APs.append(AP)\n",
        "    mAP = np.mean(APs)\n",
        "    return mAP\n",
        "\n",
        "# train dataset\n",
        "train_set = CustomDataset()\n",
        "train_set.load_dataset(\"/content/drive/MyDrive/Project/dataset\", \"train\")\n",
        "train_set.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "val_set = CustomDataset()\n",
        "val_set.load_dataset(\"/content/drive/MyDrive/Project/dataset\", \"val\")\n",
        "val_set.prepare()\n",
        "\n",
        "# create config\n",
        "cfg = PredictionConfig()\n",
        "# define the model\n",
        "model = modellib.MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
        "# load model weights\n",
        "model.load_weights('/content/drive/MyDrive/Project/logs/object20220422T0302/mask_rcnn_object_0080.h5', by_name=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3X4gRY_GX4s",
        "outputId": "4e914c6e-fee7-41f9-e301-c4e5747561cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9835958005249343\n"
          ]
        }
      ],
      "source": [
        "# evaluate model on train dataset\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(train_mAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpqeUdCUGdAK",
        "outputId": "bd5e85ce-5304-4b5d-cbe7-b1d291b539aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.925\n"
          ]
        }
      ],
      "source": [
        "# evaluate model on test dataset\n",
        "val_mAP = evaluate_model(val_set, model, cfg)\n",
        "print(val_mAP)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TrainFile.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
